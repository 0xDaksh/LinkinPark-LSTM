{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import random\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://gist.githubusercontent.com/DakshMiglani/a51e2c70d20f4d048521440c7b1a421f/raw/1b3240c63714a23626f2548d2f3ca61d50fc5acb/data.txt\n",
      "16384/40339 [===========>..................] - ETA: 0sText Length: 40299\n"
     ]
    }
   ],
   "source": [
    "path = get_file('data.txt', origin='https://gist.githubusercontent.com/DakshMiglani/a51e2c70d20f4d048521440c7b1a421f/raw/1b3240c63714a23626f2548d2f3ca61d50fc5acb/data.txt')\n",
    "text = open(path).read().lower()\n",
    "print('Text Length:', len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 36\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "print('total chars:', len(chars))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Sequences: 13410\n"
     ]
    }
   ],
   "source": [
    "maxlen = 70\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "print('Total Sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing Text...\n"
     ]
    }
   ],
   "source": [
    "print('Vectorizing Text...')\n",
    "X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    }
   ],
   "source": [
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filepath=\"weights/Chester Loss {loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def genText(start_index, maxlen):\n",
    "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('----- Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyric(start_index, maxlen, c):\n",
    "    for diversity in c:\n",
    "        print()\n",
    "        print('----- diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(650):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_gen(epochs, end):\n",
    "    for iteration in range(1, epochs):\n",
    "        print()\n",
    "        print('-' * 50)\n",
    "        print('Iteration', iteration)\n",
    "        model.fit(X, y,\n",
    "                  batch_size=128,\n",
    "                  epochs=1,\n",
    "                 callbacks=callbacks_list)\n",
    "\n",
    "        start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "        if iteration % end == 0:\n",
    "            genText(start_index, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_model(fin):\n",
    "    model.load_weights(fin)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "load_model('weights/Chester Loss 0.0043.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lyricFromSentence(sentence, maxlen, c):\n",
    "    for diversity in c:\n",
    "        generated = ''\n",
    "        generated += sentence\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(650):\n",
    "            x = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yeah, i drive my self crazy, cause i cant escape the gravity holding on\n",
      "so much more than i can carry\n",
      "i keep dragging around what's bringing me down\n",
      "if i just let go, i'd be set free\n",
      "holding on\n",
      "why is everything so heavy?\n",
      "\n",
      "want i want to down\n",
      "when they turn down the lights\n",
      "\n",
      "i hear the turn\n",
      "cand a gave my end\n",
      "thing\n",
      "shough the face inside is right beneath your skin\n",
      "the ground me just the same\n",
      "and fan the flames\n",
      "as your blazes burn\n",
      "\n",
      "and don't got that i can't be whit\n",
      "\n",
      "i feal the fact inside is here my time when\n",
      "\n",
      "i trutt the turn\n",
      "can yeauped\n",
      "i'm sick of feeling\n",
      "is there nothing you can say?\n",
      "take this all away\n",
      "i'm suffocating!\n",
      "tell me what the fuck is wrong with me!\n",
      ", all alount the alrout to be whole again\n",
      "\n",
      "'cuus w\n"
     ]
    }
   ],
   "source": [
    "lyricFromSentence(\"yeah, i drive my self crazy, cause i cant escape the gravity holding o\", maxlen, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you say that i am paranoid, but i am pretty sure the world is out get me\n",
      "i real\n",
      "i want to figut the words roome\n",
      "so the sun will set for you\n",
      "as fall\n",
      "can't be outfought\n",
      "it can't be outdone\n",
      "it can't out all the rest\n",
      "\n",
      "i want to be in the only race\n",
      "i can't be whe yound you there\n",
      "if the face inside is right beneath my skin\n",
      "it shour want you to what i haven't got\n",
      "\n",
      "i want to be in the far the pain and the shadow of the universe\n",
      "but you keep spinning 'round me just the same\n",
      "and fan the flames\n",
      "as your blazes burn\n",
      "\n",
      "and i  the pain anot the pain the pain anot\n",
      "the final masquerade\n",
      "\n",
      "the final masquerade\n",
      "\n",
      "the final masquerade\n",
      "\n",
      "the find and the goad\n",
      "you feel loadn to the ground\n",
      "\n",
      "when you feel like the fact inside is how i fall\n"
     ]
    }
   ],
   "source": [
    "lyricFromSentence(\"you say that i am paranoid, but i am pretty sure the world is out get \", maxlen, [0.7])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
